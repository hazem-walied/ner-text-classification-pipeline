{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-18T13:55:51.940549Z",
     "iopub.status.busy": "2025-04-18T13:55:51.940323Z",
     "iopub.status.idle": "2025-04-18T13:55:54.022799Z",
     "shell.execute_reply": "2025-04-18T13:55:54.021973Z",
     "shell.execute_reply.started": "2025-04-18T13:55:51.940531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T13:55:59.794618Z",
     "iopub.status.busy": "2025-04-18T13:55:59.794136Z",
     "iopub.status.idle": "2025-04-18T13:56:04.048766Z",
     "shell.execute_reply": "2025-04-18T13:56:04.048260Z",
     "shell.execute_reply.started": "2025-04-18T13:55:59.794597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building BILSTM-CRF (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T14:14:13.117689Z",
     "iopub.status.busy": "2025-04-18T14:14:13.117116Z",
     "iopub.status.idle": "2025-04-18T14:14:13.135323Z",
     "shell.execute_reply": "2025-04-18T14:14:13.134625Z",
     "shell.execute_reply.started": "2025-04-18T14:14:13.117666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim=100, hidden_dim=128, num_layers=1, dropout=0.5):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim // 2,  \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=True,\n",
    "                           dropout=dropout if num_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        # Maps the output of the LSTM into tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        \n",
    "        # Matrix of transition parameters\n",
    "        # transitions[i, j] is the score of transitioning from j to i\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "        \n",
    "        # These two statements enforce constraints on the transitions:\n",
    "        # 1. Don't transition to the padding tag\n",
    "        # 2. Don't transition from the padding tag\n",
    "        self.transitions.data[tag_to_ix[\"<PAD>\"], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[\"<PAD>\"]] = -10000\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def _get_lstm_features(self, input_ids, attention_mask):\n",
    "        # Get sequence lengths from attention mask\n",
    "        seq_lengths = attention_mask.sum(dim=1).cpu()\n",
    "        \n",
    "        # Embed the tokens\n",
    "        embeds = self.word_embeds(input_ids)\n",
    "        embeds = self.dropout(embeds)\n",
    "        \n",
    "        # Pack padded sequence for LSTM\n",
    "        packed = pack_padded_sequence(embeds, seq_lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(packed)\n",
    "        \n",
    "        # Unpack sequence\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        # Apply dropout\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Project to tag space\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        \n",
    "        return lstm_feats\n",
    "    \n",
    "    def _score_sentence(self, feats, tags, mask):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        batch_size, seq_len, _ = feats.shape\n",
    "        \n",
    "        score = torch.zeros(batch_size, device=feats.device)\n",
    "        \n",
    "        # Add transition from start tag to first tag for each sequence\n",
    "        start_tags = torch.full((batch_size, 1), self.tag_to_ix[\"<PAD>\"], dtype=torch.long, device=feats.device)\n",
    "        tags = torch.cat([start_tags, tags], dim=1)  # (batch_size, seq_len+1)\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            # Get mask for current position (batch_size)\n",
    "            mask_i = mask[:, i]\n",
    "            \n",
    "            # Emission score for current position\n",
    "            emit_score = torch.zeros(batch_size, device=feats.device)\n",
    "            emit_score[mask_i] = feats[mask_i, i, tags[mask_i, i+1]]\n",
    "            \n",
    "            # Transition score from previous to current tag\n",
    "            trans_score = torch.zeros(batch_size, device=feats.device)\n",
    "            trans_score[mask_i] = self.transitions[tags[mask_i, i+1], tags[mask_i, i]]\n",
    "            \n",
    "            # Add both scores\n",
    "            score = score + emit_score + trans_score\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _forward_alg(self, feats, mask):\n",
    "        # Forward algorithm to compute partition function\n",
    "        batch_size, seq_len, tagset_size = feats.shape\n",
    "        \n",
    "        # Initialize forward variables with -10000 (log-space)\n",
    "        alphas = torch.full((batch_size, tagset_size), -10000.0, device=feats.device)\n",
    "        # Start with all score from <PAD>\n",
    "        alphas[:, self.tag_to_ix[\"<PAD>\"]] = 0.\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            # Get mask for current position (batch_size)\n",
    "            mask_i = mask[:, i]\n",
    "            \n",
    "            # (batch_size, tagset_size, 1)\n",
    "            alphas_t = alphas.unsqueeze(2)\n",
    "            # (batch_size, 1, tagset_size)\n",
    "            emit_scores = feats[:, i].unsqueeze(1)\n",
    "            \n",
    "            # (batch_size, tagset_size, tagset_size)\n",
    "            next_tag_var = alphas_t + self.transitions + emit_scores\n",
    "            \n",
    "            # Get log sum exp over the tagset_size dimension\n",
    "            next_tag_var = torch.logsumexp(next_tag_var, dim=1)\n",
    "            \n",
    "            # âœ… Convert mask to boolean before using in torch.where\n",
    "            mask_i = mask_i.unsqueeze(1).expand_as(next_tag_var).bool()\n",
    "            alphas = torch.where(mask_i, next_tag_var, alphas)\n",
    "        \n",
    "        # Add transition to STOP_TAG (using <PAD> as stop tag here)\n",
    "        terminal_var = alphas + self.transitions[self.tag_to_ix[\"<PAD>\"]]\n",
    "        alphas = torch.logsumexp(terminal_var, dim=1)\n",
    "        \n",
    "        return alphas\n",
    "\n",
    "    \n",
    "    def neg_log_likelihood(self, input_ids, tags, attention_mask):\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        feats = self._get_lstm_features(input_ids, attention_mask)\n",
    "        \n",
    "        # Find the best path, and the score of that path\n",
    "        forward_score = self._forward_alg(feats, attention_mask)\n",
    "        gold_score = self._score_sentence(feats, tags, attention_mask)\n",
    "        \n",
    "        # Return negative log likelihood\n",
    "        return torch.mean(forward_score - gold_score)\n",
    "    \n",
    "    def _viterbi_decode(self, feats, mask):\n",
    "        # Find the best path using Viterbi algorithm\n",
    "        batch_size, seq_len, tagset_size = feats.shape\n",
    "        \n",
    "        # Initialize backpointers and viterbi variables\n",
    "        backpointers = torch.zeros((batch_size, seq_len, tagset_size), dtype=torch.long, device=feats.device)\n",
    "        \n",
    "        # Initialize viterbi variables with -10000 (log-space)\n",
    "        viterbi_vars = torch.full((batch_size, tagset_size), -10000.0, device=feats.device)\n",
    "        viterbi_vars[:, self.tag_to_ix[\"<PAD>\"]] = 0\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            # Get mask for current position (batch_size)\n",
    "            mask_i = mask[:, i]\n",
    "            \n",
    "            # (batch_size, tagset_size, 1)\n",
    "            viterbi_vars_t = viterbi_vars.unsqueeze(2)\n",
    "            # (batch_size, tagset_size, tagset_size)\n",
    "            viterbi_scores = viterbi_vars_t + self.transitions\n",
    "            \n",
    "            # Find the best tag for each previous tag\n",
    "            # (batch_size, tagset_size)\n",
    "            best_tag_id = torch.argmax(viterbi_scores, dim=1)\n",
    "            best_scores = torch.gather(viterbi_scores, 1, best_tag_id.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Add emission scores\n",
    "            best_scores = best_scores + feats[:, i]\n",
    "            \n",
    "            # Save backpointers and best scores\n",
    "            backpointers[:, i, :] = best_tag_id\n",
    "            \n",
    "            # Set viterbi variables if mask is valid, otherwise keep previous value\n",
    "            mask_i = mask_i.unsqueeze(1).expand_as(best_scores)\n",
    "            viterbi_vars = torch.where(mask_i, best_scores, viterbi_vars)\n",
    "        \n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = viterbi_vars + self.transitions[self.tag_to_ix[\"<PAD>\"]]\n",
    "        best_tag_id = torch.argmax(terminal_var, dim=1)\n",
    "        \n",
    "        # Follow the backpointers to decode the best path\n",
    "        best_path = torch.zeros((batch_size, seq_len), dtype=torch.long, device=feats.device)\n",
    "        \n",
    "        # Start with the best tag for the last position\n",
    "        best_path[:, -1] = best_tag_id\n",
    "        \n",
    "        # Follow the backpointers to find the best path\n",
    "        for i in range(seq_len-2, -1, -1):\n",
    "            # Get the best tag for the current position based on the next tag\n",
    "            best_tag_id = torch.gather(\n",
    "                backpointers[:, i+1, :], \n",
    "                1, \n",
    "                best_path[:, i+1].unsqueeze(1)\n",
    "            ).squeeze(1)\n",
    "            \n",
    "            # Only update positions where mask is valid\n",
    "            mask_i = mask[:, i+1]\n",
    "            best_path[:, i] = torch.where(mask_i, best_tag_id, torch.zeros_like(best_tag_id))\n",
    "        \n",
    "        return best_path\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(input_ids, attention_mask)\n",
    "        \n",
    "        # Find the best path using Viterbi algorithm\n",
    "        tag_seq = self._viterbi_decode(lstm_feats, attention_mask)\n",
    "        \n",
    "        return tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T14:11:46.813101Z",
     "iopub.status.busy": "2025-04-18T14:11:46.812566Z",
     "iopub.status.idle": "2025-04-18T14:11:46.821767Z",
     "shell.execute_reply": "2025-04-18T14:11:46.821004Z",
     "shell.execute_reply.started": "2025-04-18T14:11:46.813076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_bilstm_crf(model, train_loader, val_loader, device, epochs=10, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for batch in progress_bar:\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            tags = batch['tags'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            loss = model.neg_log_likelihood(input_ids, tags, attention_mask)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': total_loss / (progress_bar.n + 1)})\n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]')\n",
    "            for batch in progress_bar:\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                tags = batch['tags'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                loss = model.neg_log_likelihood(input_ids, tags, attention_mask)\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_loss += loss.item()\n",
    "                progress_bar.set_postfix({'loss': val_loss / (progress_bar.n + 1)})\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "            print(f'New best model saved with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T14:14:23.519619Z",
     "iopub.status.busy": "2025-04-18T14:14:23.519032Z",
     "iopub.status.idle": "2025-04-18T14:16:57.709897Z",
     "shell.execute_reply": "2025-04-18T14:16:57.709146Z",
     "shell.execute_reply.started": "2025-04-18T14:14:23.519594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 983k/983k [00:01<00:00, 758kB/s] \n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14041/14041 [00:01<00:00, 7184.17 examples/s]\n",
      "Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3250/3250 [00:00<00:00, 6091.06 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3453/3453 [00:00<00:00, 7641.89 examples/s]\n",
      "Building vocabulary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14041/14041 [00:01<00:00, 9794.58it/s]\n",
      "Building vocabulary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3250/3250 [00:00<00:00, 10671.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [01:35<00:00,  4.60it/s, loss=5.18e+3]\n",
      "Epoch 1/5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:06<00:00, 15.33it/s, loss=2.28e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 5178.6807, Val Loss: 2261.7244\n",
      "New best model saved with validation loss: 2261.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [01:55<00:00,  3.82it/s, loss=3.62e+3]\n",
      "Epoch 2/5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:06<00:00, 14.60it/s, loss=716]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 3624.9354, Val Loss: 716.1565\n",
      "New best model saved with validation loss: 716.1565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [01:36<00:00,  4.55it/s, loss=2.08e+3]\n",
      "Epoch 3/5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:06<00:00, 16.45it/s, loss=-781]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 2076.3720, Val Loss: -773.2838\n",
      "New best model saved with validation loss: -773.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [01:36<00:00,  4.53it/s, loss=960]    \n",
      "Epoch 4/5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:07<00:00, 14.32it/s, loss=-2.34e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 960.2039, Val Loss: -2313.8004\n",
      "New best model saved with validation loss: -2313.8004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [01:57<00:00,  3.73it/s, loss=-612]   \n",
      "Epoch 5/5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:07<00:00, 13.43it/s, loss=-3.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: -611.9151, Val Loss: -3817.7824\n",
      "New best model saved with validation loss: -3817.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load NER dataset\n",
    "ner_dataset = load_dataset(\"conll2003\",trust_remote_code=True)\n",
    "\n",
    "ner_train_dataset = NERDataset(ner_dataset['train'])\n",
    "ner_val_dataset = NERDataset(ner_dataset['validation'])\n",
    "\n",
    "# Create DataLoaders\n",
    "ner_train_loader = DataLoader(ner_train_dataset, batch_size=32, shuffle=True)\n",
    "ner_val_loader = DataLoader(ner_val_dataset, batch_size=32)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = BiLSTM_CRF(\n",
    "    vocab_size=len(ner_train_dataset.word2idx),\n",
    "    tag_to_ix=ner_train_dataset.tag2idx,\n",
    "    embedding_dim=100,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "# Train model\n",
    "trained_model = train_bilstm_crf(\n",
    "    model=model,\n",
    "    train_loader=ner_train_loader,\n",
    "    val_loader=ner_val_loader,\n",
    "    device=device,\n",
    "    epochs=5,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "torch.save(trained_model.state_dict(), 'bilstm_crf_ner.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
